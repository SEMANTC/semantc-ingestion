# src/client/graphql_client.py
import requests
import time
import logging
from typing import Dict, List, Optional, Tuple

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ShopifyGraphQLClient:
    """
    SHOPIFY GRAPHQL CLIENT WITH RATE LIMITING, ERROR HANDLING, AND PAGINATION
    """
    
    def __init__(self, shop_url: str, access_token: str):
        """
        Initialize Shopify GraphQL client
        
        Args:
            shop_url: Shop's myshopify.com domain
            access_token: OAuth access token
        """
        self.shop_url = shop_url
        self.endpoint = f"https://{shop_url}/admin/api/2024-10/graphql.json"
        self.headers = {
            "Content-Type": "application/json",
            "X-Shopify-Access-Token": access_token
        }
        self.available_points = 1000  # Default cost points bucket
        self.last_response_points = 0
        
    def _handle_response(self, response: requests.Response) -> Tuple[Dict, bool]:
        """
        Handle GraphQL response and rate limits
        
        Returns:
            Tuple[response_data, should_retry]
        """
        # Track cost points from response headers
        cost_points = response.headers.get('X-Shopify-Shop-Api-Call-Limit', '0/1000')
        self.available_points = int(cost_points.split('/')[0])
        
        data = response.json()
        
        # Check for GraphQL errors
        if 'errors' in data:
            errors = data['errors']
            for error in errors:
                error_code = error.get('extensions', {}).get('code', '')
                error_message = error.get('message', 'Unknown error')
                
                # Handle specific error codes
                if error_code == 'THROTTLED':
                    retry_after = int(response.headers.get('Retry-After', 5))
                    logger.warning(f"Rate limited. Waiting {retry_after} seconds. Error: {error_message}")
                    time.sleep(retry_after)
                    return data, True
                    
                elif error_code == 'INTERNAL_SERVER_ERROR':
                    logger.error(f"Shopify server error: {error_message}")
                    return data, True
                    
                else:
                    logger.error(f"GraphQL error: {error_message}")
                    return data, False
                    
        return data, False

    def execute_query(self, query: str, variables: Optional[Dict] = None) -> Dict:
        """
        Execute GraphQL query with error handling and retries
        
        Args:
            query: GraphQL query string
            variables: Optional query variables
            
        Returns:
            Dict containing the query response
            
        Raises:
            Exception: When max retries are exceeded or unrecoverable error occurs
        """
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                response = requests.post(
                    self.endpoint,
                    json={"query": query, "variables": variables},
                    headers=self.headers,
                    timeout=30  # 30 seconds timeout
                )
                
                # Handle 200 responses with potential errors
                if response.status_code == 200:
                    data, should_retry = self._handle_response(response)
                    if should_retry and retry_count < max_retries - 1:
                        retry_count += 1
                        time.sleep(2 ** retry_count)  # Exponential backoff
                        continue
                    return data
                
                # Handle non-200 responses
                response.raise_for_status()
                
            except requests.exceptions.RequestException as e:
                logger.error(f"Request failed: {str(e)}")
                if retry_count < max_retries - 1:
                    retry_count += 1
                    time.sleep(2 ** retry_count)
                    continue
                raise Exception(f"Request failed after {max_retries} retries: {str(e)}")
                
        raise Exception("Max retries exceeded")

    def fetch_paginated_data(self, query: str, resource_path: str, variables: Optional[Dict] = None) -> List[Dict]:
        """
        Fetch paginated data handling cost points
        
        Args:
            query: GraphQL query string
            resource_path: Path to the resource in response (e.g., 'orders.edges.node')
            variables: Optional query variables
            
        Returns:
            List of resources
        """
        if variables is None:
            variables = {}
            
        all_data = []
        has_next_page = True
        variables['first'] = 50  # Default page size
        
        while has_next_page:
            # Check if we need to pause for rate limits
            if self.available_points < 100:  # Buffer for safety
                logger.info("Approaching rate limit, pausing for 5 seconds...")
                time.sleep(5)
            
            result = self.execute_query(query, variables)
            
            if 'data' not in result:
                logger.warning(f"No data in response for {resource_path}")
                break
                
            data = result['data']
            page_data = self._extract_data(data, resource_path)
            all_data.extend(page_data)
            
            # Get pagination info
            page_info = self._get_page_info(data, resource_path)
            has_next_page = page_info.get('hasNextPage', False)
            
            if has_next_page:
                variables['after'] = page_info.get('endCursor')
                logger.info(f"Fetched {len(all_data)} {resource_path} records. Fetching next page...")
                
        logger.info(f"Completed fetching {len(all_data)} {resource_path} records")
        return all_data

    def _extract_data(self, data: Dict, path: str) -> List[Dict]:
        """
        Extract data from response following the path
        """
        parts = path.split('.')
        current = data
        
        for part in parts:
            if part == 'edges':
                current = [edge['node'] for edge in current.get(part, [])]
            else:
                current = current.get(part, {})
                
        return current if isinstance(current, list) else []

    def _get_page_info(self, data: Dict, resource_path: str) -> Dict:
        """
        Get pagination info from response
        """
        base_path = resource_path.split('.')[0]
        return data.get(base_path, {}).get('pageInfo', {})